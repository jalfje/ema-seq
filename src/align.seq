## align.seq
## Script which performs EMA alignment.

from data import *
from samrecord import *

def find_clouds_and_align_standard_fastq(fq1_file, fq2_file, out_file, apply_opt, tech, read_group, threads_per_file):
    pass # Likely will not implement, but might

def find_clouds_and_align_special_fastq(fqx_file, out_file, apply_opt, tech, read_group, threads_per_file):
    fq1, fq2 = read_special_fastq(fqx_file)
    assert(len(fq1) == len(fq2))

    # TODO: parallelize by threads_per_file
    MAX_CLOUDS_PER_BC_LARGE = 10000000
    MAX_CLOUDS_PER_BC_SMALL = 1000000
    EM_ITERS = 5
    max_clouds = MAX_CLOUDS_PER_BC_LARGE if tech.many_clouds else MAX_CLOUDS_PER_BC_SMALL
    read_group_id = str() if len(read_group) == 0 else read_group[read_group.index("ID:")+3:]

    bc_group_end_idx = 0
    total_records = len(fq1)
    sam_dict: SamDict # TODO: implement this? or else convert to simple dict. but this has more functionality.
    while bc_group_end_idx < total_records:
        clouds = list[Cloud]()

        ### Get barcode group
        fq1_bc_group_range = seek_next_barcode_group(fq1, bc_group_end_idx)
        fq2_bc_group_range = seek_next_barcode_group(fq2, bc_group_end_idx)
        assert(fq1_bc_group_range == fq2_bc_group_range)
        bc_range = fq1_bc_group_range # once verified as equal, simplify name

        bc_group_end_idx = bc_range[1] # update end index for outer loop

        barcode = fq1[bc_range[0]].barcode # get actual barcode
        worth_doing_full_em = (bc_range[1] - bc_range[0]) >= 30

        # TODO: ensure ref and opts are accessible here.
        ### Generate list of alignments for reads in this barcode group
        sam_records = [get_alignments(ref, opts, mate1, mate2) for mate1, mate2 in zip(fq1[bc_range[0], bc_range[1]], fq2[bc_range[0], bc_range[1]])]

        n_records_final = 0
        records_final = list[SamRecord](2 * (bc_range[1] - bc_range[0]))

        sam_records = sorted(sam_records, cmp=sam_record_cmp)

        ### Find and process clouds
        r_idx = 0
        while r_idx < len(sam_records) and sam_records[r_idx].barcode == barcode:
            r_start_idx = r_idx
            assert(len(clouds) < max_clouds)
            cloud = Cloud()
            clouds.append(cloud)

            sam_dict.add(sam_records[r_idx], cloud, force=False)
            cov = 1
            collision_detected = False
            while (r_idx+1 < len(sam_records) and
                   sam_records[r_idx+1].barcode == sam_records[r_idx].barcode and
                   sam_records[r_idx+1].chrom == sam_records[r_idx].chrom and
                   sam_records[r_idx+1].pos - sam_records[r_idx].pos <= tech.dist_thresh):
                r_idx += 1

                if not collision_detected and sam_dict.add(sam_records[r_idx], cloud, force=False):
                    collision_detected = True
                    for idx in range(cov):
                        sam_dict.delete(sam_records[r_start_idx+idx]) # TODO: implement sam_dict.delete(SamRecord)

                cov += 1

            if collision_detected:
                cloud.bad = True
                cloud_to_split = sorted(sam_records[r_start_idx:r_start_idx+cov], cmp=sam_name_cmp)

                # This is the -d flag. Not implementing for the project.
                #if apply_opt:
                #    mark_optimal_alignments_in_cloud(cloud_to_split)

                for rec in cloud_to_split:
                    sam_dict.add(rec, cloud, force=True) # TODO: implement sam_dict.add(SamRecord, Cloud, force)

            r_idx += 1

        ### Initializations
        for e in sam_dict.entries(): # TODO: implement sam_dict.entries()
            e.gammas = normalize_log_probabilities(e.gammas)

            for cloud, gamma in zip(e.clouds, e.gammas):
                cloud.exp_cov += gamma

        # Compute cloud scores
        for cloud in clouds:
            cloud.weight = cloud.exp_cov

        if not tech.many_clouds:
            normalize_cloud_probabilities(clouds)

        ### Expectation-Maximization iterations
        for q in range(EM_ITERS):
            if not worth_doing_full_em:
                break

            old_gammas = list[float]()
            max_change = 0.0

            for cloud in clouds:
                cloud.exp_cov = 0.0

            # Recompute gammas
            for e in sam_dict.entries():
                pass # TODO: TODO: TODO:

            for e in sam_dict.entries():
                for r, c, g in zip(e.cand_records, e.cand_clouds, e.gammas):
                    if r.active and not r.duplicate:
                        c.exp_cov += g

            # Recompute cloud scores
            for cloud in clouds:
                cloud.weight = cloud.exp_cov

            if not tech.many_clouds:
                normalize_cloud_probabilities(clouds)

        ### Find best alignments
        # TODO:

        ### Skip duplicates
        if not tech.many_clouds:
            records_final = sorted(records_final, cmp=sam_duplicate_cmp)

            i = 0
            while i < n_records_final:
                j = i + 1
                while j < n_records_final and sam_duplicate_cmp(records_final[i], records_final[j]) == 0:
                    records_final[j].duplicate = True
                    j += 1
                i = j

        # TODO: implement print_sam_record(mate1, mate2, out_file, readgroupid)
        ### Print records
        for record in records_final:
            if record.visited:
                continue

            mate = record.selected_mate
            if mate != None:
                mate.visited = True

            print_sam_record(record, mate, out_file, read_group_id) # TODO: implement print_sam_record
            print_sam_record(mate, record, out_file, read_group_id)







# Compare two lines containing specially-formatted fastq records, by their barcode.
def special_fastq_record_cmp(line1: str, line2: str)-> int:
    return int(line1[0:16] > line2[0:16]) - int(line1[0:16] < line2[0:16])

# Special FASTQ file format:
#   barcode read1 id qual1 read2 qual2
#
# `read1` and `qual1` have the barcode bases/quals trimmed.
def read_special_fastq(fqx_file)-> tuple[list[FastQRecord], list[FastQRecord]]:
    records = sorted([line for line in fqx_file], cmp=special_fastq_record_cmp)

    fq1 = list[FastQRecord]()
    fq2 = list[FastQRecord]()

    for record in records:
        # values has the following format:
        # [0]: barcode [1]: read1 [2]: id [3]: qual1 [4]: read2 [5]: qual2
        values = record.split(" ")
        barcode = encode_barcode(values[0])

        fq1.append(FastQRecord(barcode, values[2], values[1], values[3]))
        fq2.append(FastQRecord(barcode, values[2], values[4], values[5]))

    return (fq1, fq2)

# Get indices of next barcode group, based on last index of previous (assumes record list sorted by barcode)
def seek_next_barcode_group(records: list[FastQRecord], start_idx: int)-> tuple[int, int]:
    idx = start_idx
    barcode = records[idx].barcode
    while idx < len(records) and records[idx].barcode == barcode:
        idx += 1
    return (start_idx, idx)

# TODO: finish implementing subroutines/interfacing with BWA
def get_alignments(ref, opts, mate1: FastQRecord, mate2: FastQRecord)-> list[SamRecord]:
    # ref & opts are only ever passed to subcommands

    mate1_len = len(mate1.read)
    mate2_len = len(mate2.read)

    EXTRA_SEARCH_DEPTH = 12

    # TODO: implement
    alignments: EasyAlignmentPairs = bwa_mem_mate_sw(ref, opts, mate1.read, mate1_len, mate2.read, mate2_len, 25)
    best_dist = -1
    aligns_added1 = 0
    aligns_added2 = 0

    sam_records = list[SamRecord]()

    is_first = True
    for a in alignments.a1:
        # TODO: implement
        r: SingleReadAlignment = bwa_smith_waterman(ref, opts, mate1.read, mate1_len, a.chained_hit)

        clip = mate1_len - (a.read_end - a.read_start)

        if clip >= mate1_len / 2
            continue

        dist = r.edit_dist + clip
        if is_first = True:
            best_dist = dist
            is_first = False
        elif (dist - best_dist) > EXTRA_SEARCH_DEPTH:
            continue

        # TODO: implement
        r.mapq = mem_approx_mapq_se_insist(opts, a.chained_hit)
        # TODO: implement
        sam_records.append(alignment_to_sam_record(mate1, mate2, r, False, clip, dist))
        aligns_added1 += 1

    if aligns_added1 == 1:
        sam_records[-1].unique = True

    is_first = True
    for a in alignments.a2:
        r: SingleReadAlignment = bwa_smith_waterman(ref, opts, mate2.read, mate2_len, a.chained_hit)

        clip = mate2_len - (a.read_end - a.read_start)

        if clip >= mate2_len / 2
            continue

        dist = r.edit_dist + clip
        if is_first = True:
            best_dist = dist
            is_first = False
        elif (dist - best_dist) > EXTRA_SEARCH_DEPTH:
            continue

        r.mapq = mem_approx_mapq_se_insist(opts, a.chained_hit)
        sam_records.append(alignment_to_sam_record(mate2, mate1, r, True, clip, dist))
        aligns_added2 += 1

    if aligns_added2 == 1:
        sam_records[-1].unique = True

    return sam_records

